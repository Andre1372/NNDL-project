{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv_deep_m1_goat (Python 3.11.14)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import IPython\n",
    "\n",
    "\n",
    "# Import dei moduli che hai modificato\n",
    "import sys\n",
    "project_root = Path.cwd().parent\n",
    "\n",
    "# 2. Aggiungilo a sys.path (convertendolo in stringa)\n",
    "# abspath per sicurezza\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "    print(f\"Aggiunto al path: {project_root}\")\n",
    "sys.path.append('../src') # Assicurati che veda la cartella src\n",
    "from src.data.dataset import PianoMmapDataset\n",
    "from src.models.base_model import PianoGAN\n",
    "from src.utils.tools import piano_roll_to_pretty_midi\n",
    "from src.utils.visualization import display_prettymidi\n",
    "# Set seed per riproducibilità\n",
    "#pl.seed_everything(42)\n",
    "\n",
    "REPO_ROOT = Path('.').resolve().parent\n",
    "if REPO_ROOT not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configurazione Percorsi\n",
    "DATA_DIR = REPO_ROOT / 'data'\n",
    "MMAP_PREFIX = str(DATA_DIR / 'maestro') # Deve matchare il nome usato in preprocessing\n",
    "\n",
    "# 2. Calcolo numero totale segmenti\n",
    "# Un modo rapido è leggere la shape dal file _chords.dat che è piccolo\n",
    "chords_path = f\"{MMAP_PREFIX}_chords.dat\"\n",
    "if not Path(chords_path).exists():\n",
    "    raise FileNotFoundError(\"Esegui prima main_preprocessing.ipynb!\")\n",
    "\n",
    "# I file .dat degli accordi sono (N, 8) uint8. \n",
    "# Dimensione file in byte = N * 8.\n",
    "total_segments = Path(chords_path).stat().st_size // 8\n",
    "print(f\"Total segments found: {total_segments}\")\n",
    "\n",
    "# 3. Splitting (Copia esatta della logica di preprocessing)\n",
    "all_indices = np.arange(total_segments)\n",
    "train_idx, temp_idx = train_test_split(all_indices, test_size=0.2, random_state=42)\n",
    "val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(train_idx)} | Val: {len(val_idx)} | Test: {len(test_idx)}\")\n",
    "\n",
    "# 4. Dataset & Dataloaders\n",
    "# Nota: num_workers=0 su Windows per evitare problemi con memmap, altrimenti puoi aumentarlo\n",
    "train_ds = PianoMmapDataset(MMAP_PREFIX, train_idx)\n",
    "val_ds   = PianoMmapDataset(MMAP_PREFIX, val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iperparametri\n",
    "NOISE_DIM = 100\n",
    "LR = 0.0002\n",
    "\n",
    "# Istanza del modello\n",
    "model = PianoGAN(noise_dim=NOISE_DIM, learning_rate=LR)\n",
    "\n",
    "# (Opzionale) Stampa riassunto\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione Checkpoint (salva il modello migliore)\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath='../checkpoints',\n",
    "    filename='pianogan-{epoch:02d}-{g_loss:.2f}',\n",
    "    save_top_k=3,\n",
    "    monitor='g_loss', # O un'altra metrica se la logghi\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='auto', # se lascio auto usa in automatico la GPU\n",
    "    devices=1,\n",
    "    max_epochs=10,\n",
    ")\n",
    "\n",
    "# Avvio Training\n",
    "print(\"Starting Training...\")\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rilevamento automatico del device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Se sei su un Mac con chip M1/M2/M3 (Apple Silicon), usa 'mps' per accelerazione hardware\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using Apple MPS (Metal Performance Shaders) acceleration!\")\n",
    "else:\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "# Sposta il modello sul device corretto\n",
    "model.to(device)\n",
    "\n",
    "# --- Ora procedi con la generazione ---\n",
    "model.eval()\n",
    "\n",
    "# Prepara i dati di test\n",
    "prev, curr, chord = next(iter(val_loader))\n",
    "\n",
    "# IMPORTANTE: Anche i tensori di input devono andare sullo stesso device!\n",
    "prev = prev.to(device)\n",
    "chord = chord.to(device)\n",
    "noise = torch.randn(prev.size(0), 100, device=device)\n",
    "\n",
    "# Genera\n",
    "with torch.no_grad():\n",
    "    generated_music = model(noise, prev, chord)\n",
    "\n",
    "print(\"Generazione completata!\")\n",
    "\n",
    "# Visualize a sample from the DataLoader\n",
    "# Estrai un batch\n",
    "\n",
    "prev_bar, current_bar, chord_idx = next(iter(train_loader))\n",
    "\n",
    "print(\"Previous bars shape:\", prev_bar.shape)\n",
    "print(\"Current bars shape:\", current_bar.shape)\n",
    "print(\"Chords batch shape:\", chord_idx.shape)\n",
    "print(f\"Example chord index: {chord_idx[0].item()}\") # Stampa l'indice dell'accordo del primo campione\n",
    "\n",
    "# ho usato il codice di main_preprocessing per la visualizzazione\n",
    "\n",
    "# forse andava normalizzato (lasciato al lettore per esercizio XD)\n",
    "prev_pm = piano_roll_to_pretty_midi(prev_bar[1].squeeze().numpy()*100, fs=4)\n",
    "display_prettymidi(\n",
    "    prev_pm, \n",
    "    fs=4, \n",
    "    pitch_range=(24, 84),\n",
    "    title=f\"Visualization: previous_bar\"\n",
    ")\n",
    "current_pm = piano_roll_to_pretty_midi(current_bar[1].squeeze().numpy()*100, fs=4)\n",
    "display_prettymidi(\n",
    "    current_pm, \n",
    "    fs=4, \n",
    "    pitch_range=(24, 84),\n",
    "    title=f\"Visualization: current_bar\"\n",
    ")\n",
    "\n",
    "# Concatenate previous and current bars\n",
    "concatenated_bars = torch.cat((prev_bar[1], current_bar[1]), dim=2)  # Concatenate along time axis\n",
    "print(\"Concatenated bars shape:\", concatenated_bars.shape)\n",
    "\n",
    "concatenated_pm = piano_roll_to_pretty_midi(concatenated_bars.squeeze().numpy()*100, fs=4)\n",
    "display_prettymidi(\n",
    "    concatenated_pm, \n",
    "    fs=4, \n",
    "    pitch_range=(24, 84),\n",
    "    title=f\"Visualization: concatenated_bars\"\n",
    ")\n",
    "\n",
    "audio = IPython.display.Audio(concatenated_pm.fluidsynth(fs=16000), rate=16000)\n",
    "IPython.display.display(audio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_deep_m1_goat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
